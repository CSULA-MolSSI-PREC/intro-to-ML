{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6eb622",
   "metadata": {},
   "source": [
    "# Linear regression with scikit-learn\n",
    "\n",
    "Linear regression is one of the fundamental statistical and machine learning techniques. In this exercise, we'll use the library scikit-learn to perform linear regression to predict molecular solubilities using the dataset `delaney-processed.csv`. Unfortunately, the dataset doesn't contain all of the molecular descriptors as described in the original paper (available here: https://doi.org/10.1021/ci034243x). Nonetheless, we'll use the available descriptors as independent variables (or *features*) in the linear fit.\n",
    "\n",
    "Overall, we have two main objectives in this exercise:\n",
    "\n",
    "1. Use a linear regression model to predict solubilities for the dataset.\n",
    "2. Compute the $R^2$ statistic for the model fit.\n",
    "\n",
    "To begin, we'll first import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97566a",
   "metadata": {},
   "source": [
    "### Loading and Transforming the Data\n",
    "\n",
    "Next, we use pandas to read in our data file and create the necessary NumPy arrays of the features data (`X`) and measured solubilities (`Y`) that will be used to train the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/delaney-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f190df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3160cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X (features) and Y (solubility) values as NumPy arrays in two steps:\n",
    "# 1. Create X and Y\n",
    "# 2. Convert X and Y to NumPy arrays\n",
    "X = df.iloc[:, 2:8]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"measured log solubility in mols per litre\"]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223cd5b5",
   "metadata": {},
   "source": [
    "Before we can use the Linear Regressson model, we need to convert the `X` and `Y` from the pandas DataFrame into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e78d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8310f1",
   "metadata": {},
   "source": [
    "### Fitting the linear model\n",
    "\n",
    "Now that we have prepared our `X` and `Y` variables, let's see how we would do a fit using scikitlearn.\n",
    "\n",
    "Typically when doing fitting with scikitlearn, the first thing you will do is to import the type of model you want to use. In our case, we are importing a `LinearRegression` model. This type of model performs ordinary least squares fitting. You will first import the model, then you will create a model object. After creation, you will give data to the model and tell it to perform a fit. Your model can then be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae70d79",
   "metadata": {},
   "source": [
    "Now that you have imported the model, you can read more about it either on the [SciKitLearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) website, or by using the built-in Python `help` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15998b",
   "metadata": {},
   "source": [
    "Before we do the fit, we first create the model. Then, we specify settings for it such as if we want the linear model to have an intercept. It will have one by default, but if you wanted to do an ordinary least squares fit without an intercept, you would specify it when you create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression = LinearRegression().fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753333f",
   "metadata": {},
   "source": [
    "After we create the model, we give it data and call the `fit` function. Then, the model will contain information about coefficients and an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The coefficients are {regression.coef_} and the intercept is {regression.intercept_}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29094f",
   "metadata": {},
   "source": [
    "Remember that each coefficient above corresponds to one of the features. For example, the second coefficient (-0.01362162) tells us that for every 1 g/mol increase in molecular weight, the (log of the) molecular solubility is expected to decrease by -0.1362162. In other words, larger molecules are less soluble!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1299958",
   "metadata": {},
   "source": [
    "### Using the linear regression model to predict solubilities\n",
    "\n",
    "Now we can use our model to predict molecular solubilities and add the predictions to our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = regression.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LRmodel\"] = predicted\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173d04a",
   "metadata": {},
   "source": [
    "While our model has generated some predictions, it's difficult to tell if they are any good or if a linear regression model is even adequate. We will leave the first point alone for now and focus on the second one. (We'll come back to the first point in the next section!)\n",
    "\n",
    "One way to check if there is a linear relationship between `X` and `Y` when `X` consists of multiple features is to plot the predicted values for `Y` (which are just a function of `X`) against the actual values for `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d252b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measured vs. predicted values\n",
    "plt.scatter(df['measured log solubility in mols per litre'], df['LRmodel'])\n",
    "plt.xlabel('Measured solubilities')\n",
    "plt.ylabel('Predicted solubilities')\n",
    "\n",
    "# reference line\n",
    "x = np.linspace(-12, 2, 1000)\n",
    "plt.plot(x, x , '-g')  # solid green\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec72d46",
   "metadata": {},
   "source": [
    "The scatter plot above shows that – despite some \"noise\" – the linear regression model is generally able to predict solubilities that are \"in line\" with the measured solubilities. (See the solid green line.) This suggests that there is indeed a linear relationship between `X` and `Y` and that it was appropriate for us to try to fit a linear regression model to these data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a39683",
   "metadata": {},
   "source": [
    "### Computing $R^2$ for the fit\n",
    "\n",
    "The $R^2$ metric attempts to quantify what fraction of the variability in observed/measured `Y` values can be explained by the features `X` via a linear regression model. A model that perfectly reproduces `Y` given `X` would have an $R^2$ value of 1. A model that generates totally random predictions for `Y` would have an $R^2$ value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y, df['LRmodel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03c70f",
   "metadata": {},
   "source": [
    "We see here that the linear regression model yields an $R^2$ of approximately 0.686. One way to interpret this is to say that 68.6% of the variability in solubility can be explained by the linear regression model. This is actually quite good for a simple model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97e541",
   "metadata": {},
   "source": [
    "# Your turn: try different numbers of features\n",
    "\n",
    "Modify the code above to use different numbers of features (i.e., the values included in the data `X`). Let's choose the first five: Minimum Degree, Molecular Weight, Number of H-Bond Donors, Number of Rings, Number of Rotatable Bonds. What are the new coefficients? What is the new $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80fe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
